We would like to thank the reviewer for the helpful (insightful) comments. We truly believe that the comments have vastly improved the quality of the paper.

a. A bit more context in some places would be helpful, for instance in the first paragraph a short discussion on (a) why don’t redundant arrays need “such calibration”, (b) why would you want redundant baselines, (c) how redundant do baselines have to be?  (This last one could/should be a whole other paper, but this could at least mention some initial thoughts).

We agree with the reviewer that (a) and (b) should be added to the introduction (or be made much more explicit). We have rewritten large parts of the introduction to achive this. In regards to (c), as the reviewer also points out this is actually a topic for a future paper, which is why we chose to rather discuss a few different approaches one could follow to investigate the effect of redundacny errors in a new section Future Outlook (the last section of the paper).

b. One issue common for papers replete with linear algebra is notation.  I would suggest a glossary of notation similar to the one in Smirnov & Tasse 2015 (whose notation this paper adopts — even the “over-swoop” which is a difficult one to keep track of).  The paper uses asterisks and overbars (and “over-tildes”) without unambiguously defining them in this specific context.  This (and some other) notation just appears in the middle of section 2.  Could you give a short definition of the H’s (maybe Hermitian not needed, but Hadamard/Hessian, I probably won’t be the only needing a short primer on this — maybe give a good text reference).

We found this to be a very useful comment! We have added a glossary of notation (see Table 1). We now explicitly discuss the different overset notations used within the paper in the introduction (they are also defined in Table 1). We removed the asterisk notation from the paper and replaced it with something which is simpler. We now define Hessian and Hadamard in footnotes. We have added two good references on both of these topics, (Liu & Trenkler 2008) - Hadamard and ((Madsen et al. 2004) - Hessian.  

c. A small question, in the context of Eqs 3-6, is whether d_0 is just be ignored (you do bother to define it and you technically have N(N+1)/2 of them).  The basic question is how this is implemented in practice.

In practice d_0 is simply ignored (or it simply never occurs in practice). We have added text to Section 2 to better explain why this is in fact the case (shortly, when we iterate p and q we make sure that p < q). We define d_0, purely for the sake of mathematical completeness.

d. In Eq 13, you haven’t defined what the i-subscript means.  It seems that you use i (and j) when you want to get “at” an antenna based gain, and p, q, r, s when you sum over for other parameters.  Maybe just state your convention?

I have added a long paragraph to Section 2 which describes the indexing notation used within the paper in quite some detail. We also refer the 
reviewer to our response to comment f. Comment f is closely related to this comment. I have also added the indexing notation to the glossary table (see Table 1). 

e. Section 3 would be a good place to discuss how much redundancy is needed to be redundant in the context of generating phi.  Regarding phi, is the sentence “The function phi_{pq} is not symmetric as phi_{pg} = 0 if p >=q” a definition, or does it follow from some (unspecified?) definition?  Is zeta defined for the purposes of graphing?

The function phi can always be constructed even if the array is not redundant. It can however only be used (it is only useful) to perform redundant calibration if the following constraint is satisfied N + L <= B. We have added this constraint to Section 3. We agree that it was not
clear whether the sentence “The function phi_{pq} is not symmetric as phi_{pg} = 0 if p >=q” is a definition 
or if it follows from a definition. We have rewritten “The function phi_{pq} is not symmetric as phi_{pg} = 0 if p >=q” to clarify this (i.e. it is part of the definition). Zeta has two functions, it produces nice plots and it is used in the definition of Eq. A19.

f. In Eqs 25/26, am I guaranteed that “i-N” is in [0, L], (i.e. where y is defined)?  This probably reflects my confusion with “i” and that I haven’t fully stepped through cases.  A “scorecard” stepping through the layers of definitions would be terrific!  A flowchart?

Thank you very much for this comment! We have added a flowdiagram which details how the Jacobian can be constructed to the paper (see Figure 2). This flowchart makes a lot of things clearer to the reader: the indexing notation which is used in the matrix construction definitions, 
the allowable values these indexes can ascertain and the order in which the indices need to be traversed to construct the Jacobian matrix.

g. In Sec 3, the text that begins the simulation (top Pg 5 col 2) should probably be its own section with a bit more context content.  What kind of beam? What kind of time-binning?  Bandwidth (doesn’t matter from the flat spectrum point of view, but the visibility does)?  Maybe none of these matter in the context of the simulation, but you should convince the reader of that.  Are there plans for more realistic simulations?   Plans to apply to real data?

After carefully considering the suggestion of placing the simulation description into a seperate section we decided not to do so. We feel 
that doing so breaks the flow of the Wirtinger section too much. We did however expand the simulation description quite a bit. We added the fact that we did not include a primary beam in our simulation, nor did we consider time and frequency smearing. We also explain that we did not explicitly choose a specific integration time or channel width for our simulation (we are able to do so as our skymodel is analytic). 
These two quantitities are subsumed into a single idea, namely the SNR of your simulated visibilities (we provide reasons for using it instead of integration time and bandwidth in the paper). We plan to apply the algorithm to HERA data and in fact we have had good preliminary results in doing so. Please see our response to comment h for more details in this regard.  

h. In the conclusion, some mention of your plans going forward would be good.  Are you going to implement and use in one/all of these arrays?  How much computation/memory is needed to handle this in appropriate timescales etc?

We have added a Future Outlook section to the paper describing our roadmap for the near future. We plan to implement the algorithm on HERA data. Prelimenary results (HERA-19) indicates that we can use redundant stefcal in near real-time (to calibrate HERA). Redundant stefcal can calibrate a 10 min HERA snapshot (1024 channels) in less than 5 min (on average). Since redundant stefcal has a theoretical computational complexity of O(P^2) it seems likely that redundant stefcal would be able to calibrate the larger intermediate arrays (and final HERA array) in near real-time (if one also keeps in mind that our current redundant stefcal version does not perform any kind of paralization). Memory is not a problem, the implementer of the algorithm has to decide the data chuncks that should be loaded from disk (redundant stefcal at the moment is a per-timeslot/channel algorithm and therefore allows a lot of flexibility as to how the implementer whishes to load the data into memory - this is even more so for the paralized version of the algorithm) into memory. We do not explicitly share all of the technical details mentioned above in the Future Outlook section of the paper as we whish to share these results in a much more complete, accurate and scientific way in a future publication. Moreover, these results are preliminary at best. Instead, we present a clear roadmap of what we whish to investigate and achieve in the near future (in the Future Outlook section). We also mention some redundancy error analyses that we wish to conduct (which links with comment a) in the Future Outlook section.   
